<!DOCTYPE html>
<head>
  <title>Inverse Global Illumination using a Neural Radiometric Prior</title>
</head>
<body>
  <h2>Inverse Global Illumination using a Neural Radiometric Prior</h2>

  <p>Saeed Hadadan, Geng Lin, Jan Nov√°k, Fabrice Rousselle, Matthias Zwicker</p>

  <p>Inverse rendering methods that account for global illumination are becoming more popular, but current methods require evaluating and automatically differentiating millions of path integrals by tracing multiple light bounces, which remains expensive and prone to noise. Instead, this paper proposes a radiometric prior as a simple alternative to building complete path integrals in a traditional differentiable path tracer, while still correctly accounting for global illumination. Inspired by the Neural Radiosity technique, we use a neural network as a radiance function, and we introduce a prior consisting of the norm of the residual of the rendering equation in the inverse rendering loss. We train our radiance network and optimize scene parameters simultaneously using a loss consisting of both a photometric term between renderings and the multi-view input images, and our radiometric prior (the residual term). This residual term enforces a physical constraint on the optimization that ensures that the radiance field accounts for global illumination. We compare our method to a vanilla differentiable path tracer, and more advanced techniques such as Path Replay Backpropagation. Despite the simplicity of our approach, we can recover scene parameters with comparable and in some cases better quality, at considerably lower computation times.</p>

  <p>Webpage under construction, code available at <a href="https://github.com/inverse-neural-radiosity/inverse-neural-radiosity">GitHub</a></p>
</body>
